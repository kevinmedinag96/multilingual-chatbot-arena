{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code to create two types of personalized datasets for training (and validation):\n",
    "\n",
    "1.- Random: Original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'datasets_creator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevinmg96/miniconda3/envs/wsdm-cup/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "root_repo_directory = pathlib.Path().resolve().parent.__str__()\n",
    "sys.path.append(root_repo_directory)\n",
    "#from multilingual_chatbot_arena import initialize\n",
    "import src.constants as c\n",
    "import src.utils as utils\n",
    "import pandas as pd\n",
    "from fire import Fire\n",
    "from pydantic import BaseModel\n",
    "from typing import List,Optional,Dict,Union\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "import re\n",
    "import requests\n",
    "\n",
    "import os\n",
    "import opik\n",
    "from loguru import logger\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, AutoConfig\n",
    "from transformers.tokenization_utils import PreTrainedTokenizer\n",
    "from transformers.tokenization_utils_fast import PreTrainedTokenizerFast\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colors\n",
    "black = mcolors.CSS4_COLORS[\"black\"]\n",
    "lime = mcolors.CSS4_COLORS[\"lime\"]\n",
    "aqua = mcolors.CSS4_COLORS[\"aqua\"]\n",
    "magenta = mcolors.CSS4_COLORS[\"magenta\"]\n",
    "red = mcolors.CSS4_COLORS[\"red\"]\n",
    "grey = mcolors.CSS4_COLORS[\"grey\"]\n",
    "orange = mcolors.CSS4_COLORS[\"orangered\"]\n",
    "gold = mcolors.CSS4_COLORS[\"gold\"]\n",
    "blue = mcolors.CSS4_COLORS[\"blue\"]\n",
    "indigo = mcolors.CSS4_COLORS[\"indigo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading OG challenge's dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = root_repo_directory + c.SLASH + 'data/original'\n",
    "train_df = pd.read_parquet(path + c.SLASH + \"train.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'prompt', 'response_a', 'response_b', 'winner', 'model_a',\n",
       "       'model_b', 'language', 'num_tokens', 'num_tokens_categories'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kevinmg96/Kaggle competitions/WSDM Cup/multilingual-chatbot-arena/datasets_creator'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_repo_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48439"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_language = train_df[\"language\"].value_counts(normalize=True)[(train_df[\"language\"].value_counts(normalize=True) > 0.01).values]\n",
    "\n",
    "df_series_language = pd.DataFrame({\n",
    "    \"languages\" : series_language.keys(),\n",
    "    \"percentages\" : series_language.values * 100 \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize= (5,5))\n",
    "sns.barplot(data=df_series_language,x=\"languages\",y=\"percentages\",ax=ax,color=grey)\n",
    "\n",
    "\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.set_xlabel(\"Language\",fontsize=10)\n",
    "ax.set_ylabel(\"Percentage (%)\",fontsize=10)\n",
    "ax.set_title(\"Language's Percentage Distribution in Training Set\",fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"language\"].value_counts()[(train_df[\"language\"].value_counts() >= 10).values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"language\"].value_counts()[(train_df[\"language\"].value_counts() <= 10).values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curated - smaller datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curated dataset v0 - baseline\n",
    "This dataset consists of 5 (if possible) random records from each language. if not, then the available records\n",
    "will be sampled.\n",
    "\n",
    "This baseline will be used to evaluate zero shot inference LLMs to find how well they can generalize to different\n",
    "languages, I'll load their responses in comet ML, and rank them.\n",
    "\n",
    "Results will provide a set point on fine tuning the correct (probably) LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: ('Abkhazian',)\n",
      "['model_a']\n",
      "Group: ('Afar',)\n",
      "['model_a']\n",
      "Group: ('Afrikaans',)\n",
      "['model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a']\n",
      "Group: ('Akan',)\n",
      "['model_b']\n",
      "Group: ('Albanian',)\n",
      "['model_b' 'model_a' 'model_a']\n",
      "Group: ('Amharic',)\n",
      "['model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Arabic',)\n",
      "['model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b']\n",
      "Group: ('Armenian',)\n",
      "['model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a']\n",
      "Group: ('Assamese',)\n",
      "['model_b']\n",
      "Group: ('Aymara',)\n",
      "['model_a']\n",
      "Group: ('Azerbaijani',)\n",
      "['model_b' 'model_b']\n",
      "Group: ('Bangla',)\n",
      "['model_b' 'model_b' 'model_b' 'model_b']\n",
      "Group: ('Bashkir',)\n",
      "['model_a']\n",
      "Group: ('Basque',)\n",
      "['model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a']\n",
      "Group: ('Belarusian',)\n",
      "['model_a' 'model_b' 'model_a' 'model_b']\n",
      "Group: ('Bislama',)\n",
      "['model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a']\n",
      "Group: ('Bosnian',)\n",
      "['model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b']\n",
      "Group: ('Breton',)\n",
      "['model_b' 'model_a' 'model_b']\n",
      "Group: ('Bulgarian',)\n",
      "['model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a']\n",
      "Group: ('Catalan',)\n",
      "['model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a']\n",
      "Group: ('Chinese',)\n",
      "['model_b' 'model_b' 'model_a' ... 'model_b' 'model_b' 'model_b']\n",
      "Group: ('Corsican',)\n",
      "['model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b']\n",
      "Group: ('Croatian',)\n",
      "['model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b']\n",
      "Group: ('Czech',)\n",
      "['model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Danish',)\n",
      "['model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b']\n",
      "Group: ('Dutch',)\n",
      "['model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b']\n",
      "Group: ('Dzongkha',)\n",
      "['model_b']\n",
      "Group: ('English',)\n",
      "['model_b' 'model_a' 'model_a' ... 'model_b' 'model_a' 'model_a']\n",
      "Group: ('Esperanto',)\n",
      "['model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Estonian',)\n",
      "['model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Faroese',)\n",
      "['model_b' 'model_a' 'model_a' 'model_a']\n",
      "Group: ('Finnish',)\n",
      "['model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a']\n",
      "Group: ('French',)\n",
      "['model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a']\n",
      "Group: ('Galician',)\n",
      "['model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b']\n",
      "Group: ('Ganda',)\n",
      "['model_a' 'model_b' 'model_a']\n",
      "Group: ('German',)\n",
      "['model_a' 'model_a' 'model_b' ... 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Greek',)\n",
      "['model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b']\n",
      "Group: ('Guarani',)\n",
      "['model_a']\n",
      "Group: ('Haitian Creole',)\n",
      "['model_a' 'model_a']\n",
      "Group: ('Hausa',)\n",
      "['model_a']\n",
      "Group: ('Hawaiian',)\n",
      "['model_a']\n",
      "Group: ('Hebrew',)\n",
      "['model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b']\n",
      "Group: ('Hindi',)\n",
      "['model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Hmong',)\n",
      "['model_b' 'model_b']\n",
      "Group: ('Hungarian',)\n",
      "['model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a']\n",
      "Group: ('Icelandic',)\n",
      "['model_b' 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Indonesian',)\n",
      "['model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b']\n",
      "Group: ('Interlingua',)\n",
      "['model_a' 'model_a' 'model_a' 'model_b' 'model_a']\n",
      "Group: ('Interlingue',)\n",
      "['model_b' 'model_a' 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Inuktitut',)\n",
      "['model_b' 'model_a']\n",
      "Group: ('Irish',)\n",
      "['model_b' 'model_a' 'model_a' 'model_a' 'model_a']\n",
      "Group: ('Italian',)\n",
      "['model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a']\n",
      "Group: ('Japanese',)\n",
      "['model_a' 'model_b' 'model_b' ... 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Javanese',)\n",
      "['model_a' 'model_b' 'model_a' 'model_b']\n",
      "Group: ('Kalaallisut',)\n",
      "['model_b' 'model_b']\n",
      "Group: ('Kazakh',)\n",
      "['model_a' 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Khasi',)\n",
      "['model_a' 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Khmer',)\n",
      "['model_a']\n",
      "Group: ('Kinyarwanda',)\n",
      "['model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a']\n",
      "Group: ('Klingon',)\n",
      "['model_b']\n",
      "Group: ('Korean',)\n",
      "['model_a' 'model_a' 'model_a' ... 'model_b' 'model_b' 'model_a']\n",
      "Group: ('Kurdish',)\n",
      "['model_a']\n",
      "Group: ('Kyrgyz',)\n",
      "['model_a' 'model_a' 'model_b']\n",
      "Group: ('Latin',)\n",
      "['model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a']\n",
      "Group: ('Latvian',)\n",
      "['model_a' 'model_a' 'model_b']\n",
      "Group: ('Lingala',)\n",
      "['model_b']\n",
      "Group: ('Lithuanian',)\n",
      "['model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Luxembourgish',)\n",
      "['model_b' 'model_b']\n",
      "Group: ('Macedonian',)\n",
      "['model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a']\n",
      "Group: ('Malagasy',)\n",
      "['model_b' 'model_a' 'model_a' 'model_a']\n",
      "Group: ('Malay',)\n",
      "['model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a']\n",
      "Group: ('Manx',)\n",
      "['model_b' 'model_a' 'model_b' 'model_a' 'model_a']\n",
      "Group: ('Mongolian',)\n",
      "['model_b' 'model_b' 'model_a']\n",
      "Group: ('Nauru',)\n",
      "['model_a' 'model_a' 'model_a' 'model_b']\n",
      "Group: ('Norwegian',)\n",
      "['model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b']\n",
      "Group: ('Norwegian Nynorsk',)\n",
      "['model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a']\n",
      "Group: ('Nyanja',)\n",
      "['model_a' 'model_b' 'model_a']\n",
      "Group: ('Occitan',)\n",
      "['model_a' 'model_b' 'model_a' 'model_b']\n",
      "Group: ('Oromo',)\n",
      "['model_b' 'model_b' 'model_b']\n",
      "Group: ('Pashto',)\n",
      "['model_b' 'model_b']\n",
      "Group: ('Persian',)\n",
      "['model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b']\n",
      "Group: ('Polish',)\n",
      "['model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a']\n",
      "Group: ('Portuguese',)\n",
      "['model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a']\n",
      "Group: ('Quechua',)\n",
      "['model_a' 'model_b']\n",
      "Group: ('Romanian',)\n",
      "['model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a']\n",
      "Group: ('Romansh',)\n",
      "['model_a' 'model_b' 'model_b' 'model_a']\n",
      "Group: ('Rundi',)\n",
      "['model_a']\n",
      "Group: ('Russian',)\n",
      "['model_a' 'model_b' 'model_a' ... 'model_b' 'model_a' 'model_a']\n",
      "Group: ('Samoan',)\n",
      "['model_a' 'model_a']\n",
      "Group: ('Sanskrit',)\n",
      "['model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a']\n",
      "Group: ('Scots',)\n",
      "['model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a']\n",
      "Group: ('Scottish Gaelic',)\n",
      "['model_b']\n",
      "Group: ('Serbian',)\n",
      "['model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a']\n",
      "Group: ('Shona',)\n",
      "['model_a']\n",
      "Group: ('Sindhi',)\n",
      "['model_b']\n",
      "Group: ('Slovak',)\n",
      "['model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a']\n",
      "Group: ('Slovenian',)\n",
      "['model_a' 'model_a' 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Southern Sotho',)\n",
      "['model_b' 'model_b' 'model_a']\n",
      "Group: ('Spanish',)\n",
      "['model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Sundanese',)\n",
      "['model_a' 'model_a']\n",
      "Group: ('Swahili',)\n",
      "['model_b' 'model_b']\n",
      "Group: ('Swati',)\n",
      "['model_a' 'model_a']\n",
      "Group: ('Swedish',)\n",
      "['model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b']\n",
      "Group: ('Tagalog',)\n",
      "['model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b']\n",
      "Group: ('Tamil',)\n",
      "['model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b']\n",
      "Group: ('Tatar',)\n",
      "['model_b' 'model_b' 'model_b' 'model_a' 'model_a']\n",
      "Group: ('Telugu',)\n",
      "['model_b']\n",
      "Group: ('Thai',)\n",
      "['model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a']\n",
      "Group: ('Tibetan',)\n",
      "['model_b' 'model_a']\n",
      "Group: ('Tongan',)\n",
      "['model_a' 'model_a' 'model_a']\n",
      "Group: ('Tsonga',)\n",
      "['model_a' 'model_b' 'model_b']\n",
      "Group: ('Tswana',)\n",
      "['model_b' 'model_b']\n",
      "Group: ('Turkish',)\n",
      "['model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b']\n",
      "Group: ('Turkmen',)\n",
      "['model_b' 'model_a' 'model_b']\n",
      "Group: ('Ukrainian',)\n",
      "['model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b']\n",
      "Group: ('Uzbek',)\n",
      "['model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b']\n",
      "Group: ('Vietnamese',)\n",
      "['model_b' 'model_a' 'model_b' ... 'model_a' 'model_a' 'model_a']\n",
      "Group: ('Volapk',)\n",
      "['model_a' 'model_b']\n",
      "Group: ('Waray',)\n",
      "['model_b']\n",
      "Group: ('Welsh',)\n",
      "['model_a' 'model_a' 'model_a' 'model_b' 'model_a']\n",
      "Group: ('Wolof',)\n",
      "['model_a' 'model_a' 'model_a' 'model_b']\n",
      "Group: ('Xhosa',)\n",
      "['model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b']\n",
      "Group: ('Yiddish',)\n",
      "['model_b']\n",
      "Group: ('Yoruba',)\n",
      "['model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b']\n",
      "Group: ('Zhuang',)\n",
      "['model_a']\n",
      "Group: ('unknown',)\n",
      "['model_a' 'model_a' 'model_b' ... 'model_b' 'model_a' 'model_a']\n",
      "Group: ('xx',)\n",
      "['model_a' 'model_b' 'model_a' 'model_b']\n",
      "Group: ('zzp',)\n",
      "['model_b' 'model_a']\n"
     ]
    }
   ],
   "source": [
    "groupby_language = train_df.groupby([\"language\"])\n",
    "\n",
    "for name, group in groupby_language:\n",
    "    print(f\"Group: {name}\")\n",
    "    print(group['winner'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_125265/2821983180.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  curated_df_v0 = groupby_language.apply(func,**kwargs).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "def func(x,**kwargs):\n",
    "\n",
    "    kwargs['generator'].shuffle(x.to_numpy(),axis= 0)\n",
    "\n",
    "    if x.shape[0] >= kwargs['num_group_records']:\n",
    "        return x.iloc[:kwargs['num_group_records']]\n",
    "    return x\n",
    "\n",
    "\n",
    "num_group_records = 5\n",
    "generator = np.random.default_rng(seed=142)\n",
    "kwargs = {\"num_group_records\" : num_group_records, 'generator' : generator}\n",
    "\n",
    "\n",
    "\n",
    "curated_df_v0 = groupby_language.apply(func,**kwargs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118c074e1e3880f61f1ecc82b392e6ba250b4cd3bb383f...</td>\n",
       "      <td></td>\n",
       "      <td>## : \\n\\n - ...</td>\n",
       "      <td>     ...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gemini-1.5-pro-001</td>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>Abkhazian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49aa24778c38c727c3665dd418632176e523999397dc50...</td>\n",
       "      <td>devala maharshi</td>\n",
       "      <td>Devala Maharshi is a revered figure in Hinduis...</td>\n",
       "      <td>Devala Maharshi is a revered sage in Hindu myt...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>deepseek-v2.5</td>\n",
       "      <td>qwen-plus-0828</td>\n",
       "      <td>Afar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5fcf043fe50553461dcd3998c4b0a0d373d404291598ee...</td>\n",
       "      <td>Wat is de betekenis van het lied aramsamsam ?</td>\n",
       "      <td>Een interessante vraag!\\n\\n\"Aramsamsam\" (ook w...</td>\n",
       "      <td>Ik kan geen informatie vinden over een lied ge...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>llama-3.1-nemotron-70b-instruct</td>\n",
       "      <td>llama-3.1-405b-instruct-fp8</td>\n",
       "      <td>Afrikaans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>632f631eceb574551ef09a497f77405cbf146fc2e49666...</td>\n",
       "      <td>Vertel me een goede mop</td>\n",
       "      <td>Natuurlijk, hier is een klassieke mop voor je:...</td>\n",
       "      <td>Natuurlijk! Here is a classic Dutch joke for y...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>qwen-plus-0828</td>\n",
       "      <td>deepseek-v2.5</td>\n",
       "      <td>Afrikaans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c35fbab864975e41640e0e384e56c57ecc0c6bb2e4254c...</td>\n",
       "      <td>wat is de populairste bezienswaardigheid van D...</td>\n",
       "      <td>De populairste bezienswaardigheid van Duitslan...</td>\n",
       "      <td>De populairste bezienswaardigheid van Duitslan...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gemini-1.5-pro-002</td>\n",
       "      <td>glm-4-plus</td>\n",
       "      <td>Afrikaans</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0  118c074e1e3880f61f1ecc82b392e6ba250b4cd3bb383f...   \n",
       "1  49aa24778c38c727c3665dd418632176e523999397dc50...   \n",
       "2  5fcf043fe50553461dcd3998c4b0a0d373d404291598ee...   \n",
       "3  632f631eceb574551ef09a497f77405cbf146fc2e49666...   \n",
       "4  c35fbab864975e41640e0e384e56c57ecc0c6bb2e4254c...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0                                        \n",
       "1                                    devala maharshi   \n",
       "2      Wat is de betekenis van het lied aramsamsam ?   \n",
       "3                            Vertel me een goede mop   \n",
       "4  wat is de populairste bezienswaardigheid van D...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  ## : \\n\\n - ...   \n",
       "1  Devala Maharshi is a revered figure in Hinduis...   \n",
       "2  Een interessante vraag!\\n\\n\"Aramsamsam\" (ook w...   \n",
       "3  Natuurlijk, hier is een klassieke mop voor je:...   \n",
       "4  De populairste bezienswaardigheid van Duitslan...   \n",
       "\n",
       "                                          response_b   winner  \\\n",
       "0       ...  model_a   \n",
       "1  Devala Maharshi is a revered sage in Hindu myt...  model_a   \n",
       "2  Ik kan geen informatie vinden over een lied ge...  model_a   \n",
       "3  Natuurlijk! Here is a classic Dutch joke for y...  model_a   \n",
       "4  De populairste bezienswaardigheid van Duitslan...  model_a   \n",
       "\n",
       "                           model_a                      model_b   language  \n",
       "0               gemini-1.5-pro-001            gpt-4o-2024-05-13  Abkhazian  \n",
       "1                    deepseek-v2.5               qwen-plus-0828       Afar  \n",
       "2  llama-3.1-nemotron-70b-instruct  llama-3.1-405b-instruct-fp8  Afrikaans  \n",
       "3                   qwen-plus-0828                deepseek-v2.5  Afrikaans  \n",
       "4               gemini-1.5-pro-002                   glm-4-plus  Afrikaans  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curated_df_v0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(467, 8)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curated_df_v0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save V0 to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "root: str = pathlib.Path().resolve().parent.parent.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kevinmg96/Kaggle competitions/WSDM Cup/multilingual-chatbot-arena/datasets_creator'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_repo_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(root + \"/validation/validation_data_1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Below is a prompt with two possible responses (**Response A** and **Response B**). Evaluate them, select the best one and answer in the following format (it is imperative that you respect the specified format, do not add any more text than what I ask for):\\n1.- Write \\'model_a\\' if the **Response A** is better than **Response B**, otherwise write \\'model_b\\'.\\n\\n**Prompt**:\\nNoix dator Olentzero?\\n\\n**Response A**:\\nOlentzero Euskal Herriko Gabonetako pertsonaia tradizionala da. Jatorriz ikatzgilea zen eta Gabon gauean etxez etxe opariak banatzen zituen umeentzat, Gabonetako Aita bezalako papera betez. Tradizioz Olentzeroren irudia gizon zahar eta gizen bat da, bizarrarekin eta jantzi tradizionalekin. Gaur egun Olentzero Euskal Herriko Gabonetako ospakizunetan presente dago, kalejiretan eta ekitaldietan parte hartuz. Beraz, euskal kulturan oso errotuta dagoen pertsonaia da, umeentzat ilusioa eta magia dakarrena Gabonetako sasoian.\\n\\n**Response B**:\\nOlentzero es una figura tradicional del folclore vasco, que se asemeja a Santa Claus o Pap Noel en la cultura navidea de otras regiones. En el Pas Vasco y Navarra, Olentzero es quien trae los regalos a los nios el da de Navidad. \\n\\nLa frase \"Noix dator Olentzero?\" parece estar en una mezcla de euskera (vasco) y quizs una interpretacin fontica o errnea de otra lengua. Si intentamos corregirla y entenderla en el contexto vasco, podra estar intentando preguntar \"Qu nos trae Olentzero?\" o \"Qu da viene Olentzero?\", aunque gramaticalmente no es correcto en euskera estndar. \\n\\nEn euskera correcto, podras preguntar:\\n\\n- **Zer dakar Olentzerok?** - Qu trae Olentzero?\\n- **Noiz dator Olentzero?** - Cundo viene Olentzero?\\n\\nRecuerda que Olentzero viene la noche del 24 de diciembre, y los regalos se abren generalmente el 25 de diciembre por la maana. \\n\\nSi tu pregunta estaba orientada a saber ms sobre las tradiciones o lo que Olentzero suele traer, aqu tienes un poco ms de informacin:\\n\\n- **Tradiciones:** Olentzero es representado como un carbonero vasco, a veces descrito como un gigante o un hombre de montaa, que baja a los pueblos para anunciar la Navidad. La tradicin incluye cantos, desfiles y la preparacin de un gran mueco de Olentzero.\\n\\n- **Regalos:** Al igual que otras figuras navideas, Olentzero trae regalos a los nios. Estos pueden ser juguetes, libros, ropa, o cualquier cosa que los nios hayan pedido en sus cartas.\\n\\nEspero que esto aclare tu pregunta y te haya proporcionado la informacin que buscabas sobre Olentzero.\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0]['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "table = pa.Table.from_pandas(curated_df_v0)\n",
    "\n",
    "# Write Arrow Table to Parquet file\n",
    "filename = \"curated_small_v0.parquet\"\n",
    "file = root_repo_directory + c.SLASH + \"data/datasets/curated/\" + filename\n",
    "pq.write_table(table, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curated dataset v1 - Random and  uniform\n",
    "Languages: English, Russian, Chinese, Vietnamese, German, Japanese, Unknown, Korean, Spanish\n",
    "French, Portuguese, Persian, Italian, Turkish,Czech, Arabic, Polish , Ukrainian , Dutch, Hungarian\n",
    "\n",
    "\n",
    "\n",
    "100 samples per language\n",
    "\n",
    "Total samples: 2,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curated dataset v2 - Random and not uniform\n",
    "\n",
    "English, Russian, Chinese, Vietnamese, German, Japanese, Unknown, Korean :  1,000 samples\n",
    "Spanish, French, Portuguese : 500 samples\n",
    "Persian, Italian, Turkish : 200 samples\n",
    "Czech, Arabic, Polish , Ukrainian , Dutch, Hungarian : 100 samples\n",
    "\n",
    "Total samples: 8 * 1,000 + 3 * 500 + 3 * 200 + 6 * 100 = 10,700 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curated dataset v3 - Random,uniform, large multilanguages\n",
    "Languages: English, Russian, Chinese, Vietnamese, German, Japanese, Unknown, Korean, Spanish\n",
    "French, Portuguese, Persian, Italian, Turkish,Czech, Arabic, Polish , Ukrainian , Dutch, Hungarian\n",
    "\n",
    "\n",
    "100 samples per language (above)\n",
    "\n",
    "10 samples per language (below)\n",
    "\n",
    "Indonesian, Slovak, Swedish, Danish, Finnish, Serbian, Bulgarian, Hebrew, Thai, Romanian, Latin,Galician,\n",
    "Norwegian, Catalan, Greek, Lithuanian, Croatian, Sanskrit, Estonian, Scots, Basque       66\n",
    "\n",
    "\n",
    "Total samples: 20 * 100 + 21 * 10 = 2,210 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curated dataset v4 - Random,not uniform, large multilanguages\n",
    "Mix between v2 and v3.\n",
    "\n",
    "respect sampling for the languages composed in V2 and include the specified samples from v3 to the remainiding \n",
    "languages. i,e. up to Hungarian is v2, and from Indonesian and so on is v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curated dataset v5 - Random, not uniform and English biased\n",
    "\n",
    "Same as v2 except that English samples will be 10k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curated dataset v6 - Random,uniform, large multilanguages\n",
    "\n",
    "Same as v3 except that English samples will be 1k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curated dataset v7 - Random, not uniform and English biased\n",
    "\n",
    "Same as v2 except that English samples will be 2k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "English, Russian, Chinese, Vietnamese, German, Japanese, Unknown, Korean :  1,000 samples\n",
    "Spanish, French, Portuguese : 500 samples\n",
    "Persian, Italian, Turkish : 200 samples\n",
    "Czech, Arabic, Polish , Ukrainian , Dutch, Hungarian : 100 samples\n",
    "\n",
    "Total samples: 8 * 1,000 + 3 * 500 + 3 * 200 + 6 * 100 = 10,700 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x,**kwargs):\n",
    "\n",
    "    kwargs['generator'].shuffle(x.to_numpy(),axis= 0)\n",
    "\n",
    "    main_group = [\"Russian\", \"Chinese\", \"Vietnamese\", \"German\", \"Japanese\",  \"Korean\"]\n",
    "    second_group = [\"Spanish\", \"French\", \"Portuguese\"]\n",
    "    third_group = [\"Czech\", \"Arabic\", \"Polish\" , \"Ukrainian\" , \"Dutch\", \"Hungarian\"]\n",
    "\n",
    "    if x.name == \"English\":\n",
    "        return x.iloc[:kwargs[\"english_records\"]]\n",
    "    elif x.name in main_group:\n",
    "        return x.iloc[:1000]\n",
    "    elif x.name in second_group:\n",
    "        return x.iloc[:500]\n",
    "    elif x.name in third_group:\n",
    "        return x.iloc[:100]\n",
    "\n",
    "    return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_v5 = np.random.default_rng(seed=142)\n",
    "kwargs = {'generator' : generator_v5,\"english_records\" : 10000}\n",
    "\n",
    "\n",
    "\n",
    "curated_df_v5 = groupby_language.apply(func,**kwargs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save V5 to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "table = pa.Table.from_pandas(curated_df_v5)\n",
    "\n",
    "# Write Arrow Table to Parquet file\n",
    "filename = \"curated_small_v5.parquet\"\n",
    "file = root_repo_directory + c.SLASH + \"data/datasets/curated/\" + filename\n",
    "pq.write_table(table, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33736/3857405990.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  curated_df_v7 = groupby_language.apply(func,**kwargs).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "generator_v7 = np.random.default_rng(seed=142)\n",
    "kwargs = {'generator' : generator_v7, \"english_records\" : 2000}\n",
    "\n",
    "\n",
    "\n",
    "curated_df_v7 = groupby_language.apply(func,**kwargs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save V7 to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "table = pa.Table.from_pandas(curated_df_v7)\n",
    "\n",
    "# Write Arrow Table to Parquet file\n",
    "filename = \"curated_small_v7.parquet\"\n",
    "file = root_repo_directory + c.SLASH + \"data/datasets/curated/\" + filename\n",
    "pq.write_table(table, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curated dataset v8 - Random, uniform, filter by token size\n",
    "\n",
    "First filter: Conserve records whose prompt has less than 3.5k tokens\n",
    "\n",
    "Second filter: \n",
    "Languages: English, Russian, Chinese, Vietnamese, German, Japanese, Unknown, Korean, Spanish\n",
    "French, Portuguese, Persian, Italian, Turkish,Czech, Arabic, Polish , Ukrainian , Dutch, Hungarian\n",
    "\n",
    "100 samples per language (if possible)\n",
    "\n",
    "Third filter:\n",
    "Ensure that output class (model_a or model_b) is uniformly distributed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_TEMPLATE = 'You are a specialist in evaluating multilingual chat responses, with a focus on comparing and ranking outputs from different LLMs. Your primary goal is to determine which response is more likely to be preferred by humans based on factors such as clarity, relevance, tone, and overall quality.\\n'\n",
    "PROMPT_TEMPLATE = \"\"\"Below is a prompt with two possible responses (**Response A** and **Response B**). Evaluate them, select the best one and answer in the following format (it is imperative that you respect the specified format, do not add any more text than what I ask for):\\n1.- Write 'model_a' if the **Response A** is better than **Response B**, otherwise write 'model_b'.\\n\\n**Prompt**:\\n{prompt}\\n\\n**Response A**:\\n{response_a}\\n\\n**Response B**:\\n{response_b}\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model_name = \"Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "model_name,padding_side=\"left\",legacy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prompt_num_tokens(x,**kwargs):\n",
    "    tokenizer = kwargs[\"tokenizer\"]\n",
    "\n",
    "    messages = [\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_TEMPLATE},\n",
    "                    {\"role\" : \"user\", \"content\" : PROMPT_TEMPLATE.format(\n",
    "                    prompt=x.prompt,response_a=x.response_a,response_b = x.response_b)},\n",
    "                    {\"role\" : \"assistant\", \"content\" : x.winner}\n",
    "                ]\n",
    "    return len(tokenizer.apply_chat_template(messages,add_generation_prompt=True,tokenize=True))\n",
    "\n",
    "kwargs = {\n",
    "    \"tokenizer\" :tokenizer\n",
    "}\n",
    "train_df[\"num_tokens\"] = train_df.apply(add_prompt_num_tokens,axis=1,**kwargs)\n",
    "\n",
    "train_df[\"num_tokens_categories\"] = pd.cut(train_df[\"num_tokens\"],10,labels=np.arange(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1111/1205359606.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  curated_df_v8 = group_num_tokens_subset.apply(func,**kwargs).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "num_tokens_subset =train_df.query('num_tokens_categories == 0')\n",
    "group_num_tokens_subset =num_tokens_subset.groupby(\"language\")\n",
    "\n",
    "def func(x,**kwargs):\n",
    "\n",
    "    kwargs['generator'].shuffle(x.to_numpy(),axis= 0)\n",
    "\n",
    "\n",
    "    group = [\"English\",\"Russian\", \"Chinese\", \"Vietnamese\", \"German\", \"Japanese\",  \"Korean\",\n",
    "                  \"Spanish\", \"French\", \"Portuguese\",\"Persian\", \"Italian\", \"Turkish\",\n",
    "                    \"Czech\", \"Arabic\", \"Polish\" , \"Ukrainian\" , \"Dutch\", \"Hungarian\"]\n",
    "\n",
    "\n",
    "    if x.name in group:\n",
    "        return x.iloc[:kwargs[\"num_records\"]]\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "num_records = 100\n",
    "generator = np.random.default_rng(seed=142)\n",
    "kwargs = {\"num_records\" : num_records, 'generator' : generator}\n",
    "\n",
    "\n",
    "curated_df_v8 = group_num_tokens_subset.apply(func,**kwargs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assess output class distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_v8_winners = curated_df_v8.groupby([\"winner\"]).count()[\"id\"]\n",
    "\n",
    "df_series_v8_winners = pd.DataFrame({\n",
    "    \"winners\" : series_v8_winners.index.values,\n",
    "    \"percentages\" : (series_v8_winners.values / curated_df_v8.shape[0]) * 100\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, \"Model Winner's distribution for dataset v8\")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize= (5,5))\n",
    "sns.barplot(data=df_series_v8_winners,x=\"winners\",y=\"percentages\",ax=ax,color=grey)\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"Model Winner\",fontsize=10)\n",
    "ax.set_ylabel(\"Percentage (%)\",fontsize=10)\n",
    "ax.set_title(\"Model Winner's distribution for dataset v8\",fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Distribution is almost uniform, continue with the following process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>num_tokens_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01a0d5a75b02aa185ec1b183dadda41ac9af7dcccb13ae...</td>\n",
       "      <td>    prompt \\n  ...</td>\n",
       "      <td>       ...</td>\n",
       "      <td>        ...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>qwen-plus-0828</td>\n",
       "      <td>o1-preview</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>499</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03366d9255419fd5391e926f4bb1124a4b3ee726c1af1c...</td>\n",
       "      <td>     </td>\n",
       "      <td>        ...</td>\n",
       "      <td>!        ...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>yi-lightning</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>681</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03be4e6fd70afe535586561f411421970ffabf0295ff0e...</td>\n",
       "      <td>32:      ...</td>\n",
       "      <td>      ...</td>\n",
       "      <td>  </td>\n",
       "      <td>model_a</td>\n",
       "      <td>glm-4-plus</td>\n",
       "      <td>llama-3.2-3b-instruct</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03e30e488b735eb8f73e7e1d01015425fafb349de93a8d...</td>\n",
       "      <td>     15 </td>\n",
       "      <td> _testks m_\"Split \"pure to...</td>\n",
       "      <td>    15      ...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>llama-3.2-1b-instruct</td>\n",
       "      <td>gemma-2-27b-it</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>2956</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0448e77265717324f56e8fbf43a04bb363d48c1fc581fd...</td>\n",
       "      <td>        ...</td>\n",
       "      <td>      .  ...</td>\n",
       "      <td>       N ...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>glm-4-plus</td>\n",
       "      <td>llama-3.2-3b-instruct</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>1775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>07b1e1cf4944b325fe1bfed39b51c44a6626e01961d011...</td>\n",
       "      <td>nu khi hot ng di nng, da ti thng  ...</td>\n",
       "      <td>Khng, ch vi triu chng da  ln khi hot ...</td>\n",
       "      <td>Khng, ch n gin l da  ln khi tip xc ...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>mistral-large-2407</td>\n",
       "      <td>gemini-1.5-flash-8b-exp-0827</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>822</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>07d09d3b4628cdecff5361a38e3b45d7a4a800c250e2e2...</td>\n",
       "      <td>PHN TCH T KHAI HI QUAN XUT KHU B11</td>\n",
       "      <td>Phn tch t khai hi quan xut khu B11 l m...</td>\n",
       "      <td>T khai hi quan xut khu B11 l mt loi t ...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>glm-4-plus</td>\n",
       "      <td>llama-3.1-405b-instruct-bf16</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>1670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>07daa626bf958c974eda2a7deb3c85baf0eabf0fe2627f...</td>\n",
       "      <td>Bot gip kt ni cc bn thnh vin  cc bn...</td>\n",
       "      <td>Cho cc thnh vin NhiLe Team!\\n\\nTi l bot ...</td>\n",
       "      <td>Xin cho mi ngi!\\n\\nTi l Bot ca NhiLe Te...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gemini-1.5-flash-8b-001</td>\n",
       "      <td>reka-flash-20240904</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>0818baf3f947f47b1ae5d38832cf4d966299103e090ada...</td>\n",
       "      <td>L mt doanh nghip ang phn phi v bn xoi...</td>\n",
       "      <td>Di y l mt s  xut cho cc bi vit SE...</td>\n",
       "      <td>Di y l danh sch cc ch  bi vit SEO ...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>claude-3-5-sonnet-20241022</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>1422</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>0842f447bed00e3e8bfd835cad9367c6e8c5dc1ccd3131...</td>\n",
       "      <td>cho bit cch phn tch hnh vi ngi tiu dn...</td>\n",
       "      <td>Phn tch hnh vi ngi tiu dng  Cn Th v...</td>\n",
       "      <td> phn tch hnh vi ngi tiu dng  Cn Th...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>reka-flash-20240904</td>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>1156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1868 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     id  \\\n",
       "0     01a0d5a75b02aa185ec1b183dadda41ac9af7dcccb13ae...   \n",
       "1     03366d9255419fd5391e926f4bb1124a4b3ee726c1af1c...   \n",
       "2     03be4e6fd70afe535586561f411421970ffabf0295ff0e...   \n",
       "3     03e30e488b735eb8f73e7e1d01015425fafb349de93a8d...   \n",
       "4     0448e77265717324f56e8fbf43a04bb363d48c1fc581fd...   \n",
       "...                                                 ...   \n",
       "1863  07b1e1cf4944b325fe1bfed39b51c44a6626e01961d011...   \n",
       "1864  07d09d3b4628cdecff5361a38e3b45d7a4a800c250e2e2...   \n",
       "1865  07daa626bf958c974eda2a7deb3c85baf0eabf0fe2627f...   \n",
       "1866  0818baf3f947f47b1ae5d38832cf4d966299103e090ada...   \n",
       "1867  0842f447bed00e3e8bfd835cad9367c6e8c5dc1ccd3131...   \n",
       "\n",
       "                                                 prompt  \\\n",
       "0         prompt \\n  ...   \n",
       "1                              \n",
       "2     32:      ...   \n",
       "3                          15     \n",
       "4             ...   \n",
       "...                                                 ...   \n",
       "1863  nu khi hot ng di nng, da ti thng  ...   \n",
       "1864           PHN TCH T KHAI HI QUAN XUT KHU B11   \n",
       "1865  Bot gip kt ni cc bn thnh vin  cc bn...   \n",
       "1866  L mt doanh nghip ang phn phi v bn xoi...   \n",
       "1867  cho bit cch phn tch hnh vi ngi tiu dn...   \n",
       "\n",
       "                                             response_a  \\\n",
       "0            ...   \n",
       "1             ...   \n",
       "2           ...   \n",
       "3      _testks m_\"Split \"pure to...   \n",
       "4           .  ...   \n",
       "...                                                 ...   \n",
       "1863  Khng, ch vi triu chng da  ln khi hot ...   \n",
       "1864  Phn tch t khai hi quan xut khu B11 l m...   \n",
       "1865  Cho cc thnh vin NhiLe Team!\\n\\nTi l bot ...   \n",
       "1866  Di y l mt s  xut cho cc bi vit SE...   \n",
       "1867  Phn tch hnh vi ngi tiu dng  Cn Th v...   \n",
       "\n",
       "                                             response_b   winner  \\\n",
       "0             ...  model_b   \n",
       "1     !        ...  model_b   \n",
       "2                                               model_a   \n",
       "3         15      ...  model_b   \n",
       "4            N ...  model_a   \n",
       "...                                                 ...      ...   \n",
       "1863  Khng, ch n gin l da  ln khi tip xc ...  model_b   \n",
       "1864  T khai hi quan xut khu B11 l mt loi t ...  model_a   \n",
       "1865  Xin cho mi ngi!\\n\\nTi l Bot ca NhiLe Te...  model_a   \n",
       "1866  Di y l danh sch cc ch  bi vit SEO ...  model_b   \n",
       "1867   phn tch hnh vi ngi tiu dng  Cn Th...  model_a   \n",
       "\n",
       "                      model_a                       model_b    language  \\\n",
       "0              qwen-plus-0828                    o1-preview      Arabic   \n",
       "1      claude-3-opus-20240229                  yi-lightning      Arabic   \n",
       "2                  glm-4-plus         llama-3.2-3b-instruct      Arabic   \n",
       "3       llama-3.2-1b-instruct                gemma-2-27b-it      Arabic   \n",
       "4                  glm-4-plus         llama-3.2-3b-instruct      Arabic   \n",
       "...                       ...                           ...         ...   \n",
       "1863       mistral-large-2407  gemini-1.5-flash-8b-exp-0827  Vietnamese   \n",
       "1864               glm-4-plus  llama-3.1-405b-instruct-bf16  Vietnamese   \n",
       "1865  gemini-1.5-flash-8b-001           reka-flash-20240904  Vietnamese   \n",
       "1866   claude-3-opus-20240229    claude-3-5-sonnet-20241022  Vietnamese   \n",
       "1867      reka-flash-20240904        claude-3-opus-20240229  Vietnamese   \n",
       "\n",
       "      num_tokens num_tokens_categories  \n",
       "0            499                     0  \n",
       "1            681                     0  \n",
       "2            345                     0  \n",
       "3           2956                     0  \n",
       "4           1775                     0  \n",
       "...          ...                   ...  \n",
       "1863         822                     0  \n",
       "1864        1670                     0  \n",
       "1865         984                     0  \n",
       "1866        1422                     0  \n",
       "1867        1156                     0  \n",
       "\n",
       "[1868 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curated_df_v8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save V8 to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(curated_df_v8)\n",
    "\n",
    "# Write Arrow Table to Parquet file\n",
    "filename = \"curated_small_v8.parquet\"\n",
    "file = root_repo_directory + c.SLASH + \"data/datasets/curated/\" + filename\n",
    "pq.write_table(table, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsdm-cup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
