{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code to create two types of personalized datasets for training (and validation):\n",
    "\n",
    "1.- Random: Original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'datasets_creator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevinmg96/miniconda3/envs/wsdm-cup/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "root_repo_directory = pathlib.Path().resolve().parent.__str__()\n",
    "sys.path.append(root_repo_directory)\n",
    "#from multilingual_chatbot_arena import initialize\n",
    "import src.constants as c\n",
    "import src.utils as utils\n",
    "import pandas as pd\n",
    "from fire import Fire\n",
    "from pydantic import BaseModel\n",
    "from typing import List,Optional,Dict,Union\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "import re\n",
    "import requests\n",
    "\n",
    "import os\n",
    "import opik\n",
    "from loguru import logger\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, AutoConfig\n",
    "from transformers.tokenization_utils import PreTrainedTokenizer\n",
    "from transformers.tokenization_utils_fast import PreTrainedTokenizerFast\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colors\n",
    "black = mcolors.CSS4_COLORS[\"black\"]\n",
    "lime = mcolors.CSS4_COLORS[\"lime\"]\n",
    "aqua = mcolors.CSS4_COLORS[\"aqua\"]\n",
    "magenta = mcolors.CSS4_COLORS[\"magenta\"]\n",
    "red = mcolors.CSS4_COLORS[\"red\"]\n",
    "grey = mcolors.CSS4_COLORS[\"grey\"]\n",
    "orange = mcolors.CSS4_COLORS[\"orangered\"]\n",
    "gold = mcolors.CSS4_COLORS[\"gold\"]\n",
    "blue = mcolors.CSS4_COLORS[\"blue\"]\n",
    "indigo = mcolors.CSS4_COLORS[\"indigo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading OG challenge's dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = root_repo_directory + c.SLASH + 'data/original'\n",
    "train_df = pd.read_parquet(path + c.SLASH + \"train.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'prompt', 'response_a', 'response_b', 'winner', 'model_a',\n",
       "       'model_b', 'language'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kevinmg96/Kaggle competitions/WSDM Cup/multilingual-chatbot-arena/datasets_creator'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_repo_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48439"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_language = train_df[\"language\"].value_counts(normalize=True)[(train_df[\"language\"].value_counts(normalize=True) > 0.01).values]\n",
    "\n",
    "df_series_language = pd.DataFrame({\n",
    "    \"languages\" : series_language.keys(),\n",
    "    \"percentages\" : series_language.values * 100 \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize= (5,5))\n",
    "sns.barplot(data=df_series_language,x=\"languages\",y=\"percentages\",ax=ax,color=grey)\n",
    "\n",
    "\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.set_xlabel(\"Language\",fontsize=10)\n",
    "ax.set_ylabel(\"Percentage (%)\",fontsize=10)\n",
    "ax.set_title(\"Language's Percentage Distribution in Training Set\",fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"language\"].value_counts()[(train_df[\"language\"].value_counts() >= 10).values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"language\"].value_counts()[(train_df[\"language\"].value_counts() <= 10).values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curated - smaller datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curated dataset v0 - baseline\n",
    "This dataset consists of 5 (if possible) random records from each language. if not, then the available records\n",
    "will be sampled.\n",
    "\n",
    "This baseline will be used to evaluate zero shot inference LLMs to find how well they can generalize to different\n",
    "languages, I'll load their responses in comet ML, and rank them.\n",
    "\n",
    "Results will provide a set point on fine tuning the correct (probably) LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: ('Abkhazian',)\n",
      "['model_a']\n",
      "Group: ('Afar',)\n",
      "['model_a']\n",
      "Group: ('Afrikaans',)\n",
      "['model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a']\n",
      "Group: ('Akan',)\n",
      "['model_b']\n",
      "Group: ('Albanian',)\n",
      "['model_b' 'model_a' 'model_a']\n",
      "Group: ('Amharic',)\n",
      "['model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Arabic',)\n",
      "['model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b']\n",
      "Group: ('Armenian',)\n",
      "['model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a']\n",
      "Group: ('Assamese',)\n",
      "['model_b']\n",
      "Group: ('Aymara',)\n",
      "['model_a']\n",
      "Group: ('Azerbaijani',)\n",
      "['model_b' 'model_b']\n",
      "Group: ('Bangla',)\n",
      "['model_b' 'model_b' 'model_b' 'model_b']\n",
      "Group: ('Bashkir',)\n",
      "['model_a']\n",
      "Group: ('Basque',)\n",
      "['model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a']\n",
      "Group: ('Belarusian',)\n",
      "['model_a' 'model_b' 'model_a' 'model_b']\n",
      "Group: ('Bislama',)\n",
      "['model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a']\n",
      "Group: ('Bosnian',)\n",
      "['model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b']\n",
      "Group: ('Breton',)\n",
      "['model_b' 'model_a' 'model_b']\n",
      "Group: ('Bulgarian',)\n",
      "['model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a']\n",
      "Group: ('Catalan',)\n",
      "['model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a']\n",
      "Group: ('Chinese',)\n",
      "['model_b' 'model_b' 'model_a' ... 'model_b' 'model_b' 'model_b']\n",
      "Group: ('Corsican',)\n",
      "['model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b']\n",
      "Group: ('Croatian',)\n",
      "['model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b']\n",
      "Group: ('Czech',)\n",
      "['model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Danish',)\n",
      "['model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b']\n",
      "Group: ('Dutch',)\n",
      "['model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b']\n",
      "Group: ('Dzongkha',)\n",
      "['model_b']\n",
      "Group: ('English',)\n",
      "['model_b' 'model_a' 'model_a' ... 'model_b' 'model_a' 'model_a']\n",
      "Group: ('Esperanto',)\n",
      "['model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Estonian',)\n",
      "['model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Faroese',)\n",
      "['model_b' 'model_a' 'model_a' 'model_a']\n",
      "Group: ('Finnish',)\n",
      "['model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a']\n",
      "Group: ('French',)\n",
      "['model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a']\n",
      "Group: ('Galician',)\n",
      "['model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b']\n",
      "Group: ('Ganda',)\n",
      "['model_a' 'model_b' 'model_a']\n",
      "Group: ('German',)\n",
      "['model_a' 'model_a' 'model_b' ... 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Greek',)\n",
      "['model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b']\n",
      "Group: ('Guarani',)\n",
      "['model_a']\n",
      "Group: ('Haitian Creole',)\n",
      "['model_a' 'model_a']\n",
      "Group: ('Hausa',)\n",
      "['model_a']\n",
      "Group: ('Hawaiian',)\n",
      "['model_a']\n",
      "Group: ('Hebrew',)\n",
      "['model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b']\n",
      "Group: ('Hindi',)\n",
      "['model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Hmong',)\n",
      "['model_b' 'model_b']\n",
      "Group: ('Hungarian',)\n",
      "['model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a']\n",
      "Group: ('Icelandic',)\n",
      "['model_b' 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Indonesian',)\n",
      "['model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b']\n",
      "Group: ('Interlingua',)\n",
      "['model_a' 'model_a' 'model_a' 'model_b' 'model_a']\n",
      "Group: ('Interlingue',)\n",
      "['model_b' 'model_a' 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Inuktitut',)\n",
      "['model_b' 'model_a']\n",
      "Group: ('Irish',)\n",
      "['model_b' 'model_a' 'model_a' 'model_a' 'model_a']\n",
      "Group: ('Italian',)\n",
      "['model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a']\n",
      "Group: ('Japanese',)\n",
      "['model_a' 'model_b' 'model_b' ... 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Javanese',)\n",
      "['model_a' 'model_b' 'model_a' 'model_b']\n",
      "Group: ('Kalaallisut',)\n",
      "['model_b' 'model_b']\n",
      "Group: ('Kazakh',)\n",
      "['model_a' 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Khasi',)\n",
      "['model_a' 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Khmer',)\n",
      "['model_a']\n",
      "Group: ('Kinyarwanda',)\n",
      "['model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a']\n",
      "Group: ('Klingon',)\n",
      "['model_b']\n",
      "Group: ('Korean',)\n",
      "['model_a' 'model_a' 'model_a' ... 'model_b' 'model_b' 'model_a']\n",
      "Group: ('Kurdish',)\n",
      "['model_a']\n",
      "Group: ('Kyrgyz',)\n",
      "['model_a' 'model_a' 'model_b']\n",
      "Group: ('Latin',)\n",
      "['model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a']\n",
      "Group: ('Latvian',)\n",
      "['model_a' 'model_a' 'model_b']\n",
      "Group: ('Lingala',)\n",
      "['model_b']\n",
      "Group: ('Lithuanian',)\n",
      "['model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Luxembourgish',)\n",
      "['model_b' 'model_b']\n",
      "Group: ('Macedonian',)\n",
      "['model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a']\n",
      "Group: ('Malagasy',)\n",
      "['model_b' 'model_a' 'model_a' 'model_a']\n",
      "Group: ('Malay',)\n",
      "['model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a']\n",
      "Group: ('Manx',)\n",
      "['model_b' 'model_a' 'model_b' 'model_a' 'model_a']\n",
      "Group: ('Mongolian',)\n",
      "['model_b' 'model_b' 'model_a']\n",
      "Group: ('Nauru',)\n",
      "['model_a' 'model_a' 'model_a' 'model_b']\n",
      "Group: ('Norwegian',)\n",
      "['model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b']\n",
      "Group: ('Norwegian Nynorsk',)\n",
      "['model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a']\n",
      "Group: ('Nyanja',)\n",
      "['model_a' 'model_b' 'model_a']\n",
      "Group: ('Occitan',)\n",
      "['model_a' 'model_b' 'model_a' 'model_b']\n",
      "Group: ('Oromo',)\n",
      "['model_b' 'model_b' 'model_b']\n",
      "Group: ('Pashto',)\n",
      "['model_b' 'model_b']\n",
      "Group: ('Persian',)\n",
      "['model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b']\n",
      "Group: ('Polish',)\n",
      "['model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a']\n",
      "Group: ('Portuguese',)\n",
      "['model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a']\n",
      "Group: ('Quechua',)\n",
      "['model_a' 'model_b']\n",
      "Group: ('Romanian',)\n",
      "['model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a']\n",
      "Group: ('Romansh',)\n",
      "['model_a' 'model_b' 'model_b' 'model_a']\n",
      "Group: ('Rundi',)\n",
      "['model_a']\n",
      "Group: ('Russian',)\n",
      "['model_a' 'model_b' 'model_a' ... 'model_b' 'model_a' 'model_a']\n",
      "Group: ('Samoan',)\n",
      "['model_a' 'model_a']\n",
      "Group: ('Sanskrit',)\n",
      "['model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a']\n",
      "Group: ('Scots',)\n",
      "['model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a']\n",
      "Group: ('Scottish Gaelic',)\n",
      "['model_b']\n",
      "Group: ('Serbian',)\n",
      "['model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a']\n",
      "Group: ('Shona',)\n",
      "['model_a']\n",
      "Group: ('Sindhi',)\n",
      "['model_b']\n",
      "Group: ('Slovak',)\n",
      "['model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a']\n",
      "Group: ('Slovenian',)\n",
      "['model_a' 'model_a' 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Southern Sotho',)\n",
      "['model_b' 'model_b' 'model_a']\n",
      "Group: ('Spanish',)\n",
      "['model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b']\n",
      "Group: ('Sundanese',)\n",
      "['model_a' 'model_a']\n",
      "Group: ('Swahili',)\n",
      "['model_b' 'model_b']\n",
      "Group: ('Swati',)\n",
      "['model_a' 'model_a']\n",
      "Group: ('Swedish',)\n",
      "['model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b']\n",
      "Group: ('Tagalog',)\n",
      "['model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b']\n",
      "Group: ('Tamil',)\n",
      "['model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b']\n",
      "Group: ('Tatar',)\n",
      "['model_b' 'model_b' 'model_b' 'model_a' 'model_a']\n",
      "Group: ('Telugu',)\n",
      "['model_b']\n",
      "Group: ('Thai',)\n",
      "['model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a']\n",
      "Group: ('Tibetan',)\n",
      "['model_b' 'model_a']\n",
      "Group: ('Tongan',)\n",
      "['model_a' 'model_a' 'model_a']\n",
      "Group: ('Tsonga',)\n",
      "['model_a' 'model_b' 'model_b']\n",
      "Group: ('Tswana',)\n",
      "['model_b' 'model_b']\n",
      "Group: ('Turkish',)\n",
      "['model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b']\n",
      "Group: ('Turkmen',)\n",
      "['model_b' 'model_a' 'model_b']\n",
      "Group: ('Ukrainian',)\n",
      "['model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a'\n",
      " 'model_b' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_a' 'model_a' 'model_b' 'model_a' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_a' 'model_a' 'model_a' 'model_a' 'model_b' 'model_a'\n",
      " 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_b' 'model_a'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b'\n",
      " 'model_a' 'model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b'\n",
      " 'model_b' 'model_b' 'model_a' 'model_b' 'model_a' 'model_b']\n",
      "Group: ('Uzbek',)\n",
      "['model_b' 'model_a' 'model_a' 'model_b' 'model_b' 'model_a' 'model_a'\n",
      " 'model_a' 'model_b']\n",
      "Group: ('Vietnamese',)\n",
      "['model_b' 'model_a' 'model_b' ... 'model_a' 'model_a' 'model_a']\n",
      "Group: ('Volapük',)\n",
      "['model_a' 'model_b']\n",
      "Group: ('Waray',)\n",
      "['model_b']\n",
      "Group: ('Welsh',)\n",
      "['model_a' 'model_a' 'model_a' 'model_b' 'model_a']\n",
      "Group: ('Wolof',)\n",
      "['model_a' 'model_a' 'model_a' 'model_b']\n",
      "Group: ('Xhosa',)\n",
      "['model_b' 'model_a' 'model_b' 'model_a' 'model_b' 'model_b' 'model_b'\n",
      " 'model_b']\n",
      "Group: ('Yiddish',)\n",
      "['model_b']\n",
      "Group: ('Yoruba',)\n",
      "['model_b' 'model_b' 'model_a' 'model_a' 'model_a' 'model_b' 'model_b'\n",
      " 'model_b' 'model_b']\n",
      "Group: ('Zhuang',)\n",
      "['model_a']\n",
      "Group: ('unknown',)\n",
      "['model_a' 'model_a' 'model_b' ... 'model_b' 'model_a' 'model_a']\n",
      "Group: ('xx',)\n",
      "['model_a' 'model_b' 'model_a' 'model_b']\n",
      "Group: ('zzp',)\n",
      "['model_b' 'model_a']\n"
     ]
    }
   ],
   "source": [
    "groupby_language = train_df.groupby([\"language\"])\n",
    "\n",
    "for name, group in groupby_language:\n",
    "    print(f\"Group: {name}\")\n",
    "    print(group['winner'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_125265/2821983180.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  curated_df_v0 = groupby_language.apply(func,**kwargs).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "def func(x,**kwargs):\n",
    "\n",
    "    kwargs['generator'].shuffle(x.to_numpy(),axis= 0)\n",
    "\n",
    "    if x.shape[0] >= kwargs['num_group_records']:\n",
    "        return x.iloc[:kwargs['num_group_records']]\n",
    "    return x\n",
    "\n",
    "\n",
    "num_group_records = 5\n",
    "generator = np.random.default_rng(seed=142)\n",
    "kwargs = {\"num_group_records\" : num_group_records, 'generator' : generator}\n",
    "\n",
    "\n",
    "\n",
    "curated_df_v0 = groupby_language.apply(func,**kwargs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118c074e1e3880f61f1ecc82b392e6ba250b4cd3bb383f...</td>\n",
       "      <td>Макроэкономика</td>\n",
       "      <td>## Макроэкономика: Обзор\\n\\nМакроэкономика - э...</td>\n",
       "      <td>Макроэкономика — это раздел экономической наук...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gemini-1.5-pro-001</td>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>Abkhazian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49aa24778c38c727c3665dd418632176e523999397dc50...</td>\n",
       "      <td>devala maharshi</td>\n",
       "      <td>Devala Maharshi is a revered figure in Hinduis...</td>\n",
       "      <td>Devala Maharshi is a revered sage in Hindu myt...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>deepseek-v2.5</td>\n",
       "      <td>qwen-plus-0828</td>\n",
       "      <td>Afar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5fcf043fe50553461dcd3998c4b0a0d373d404291598ee...</td>\n",
       "      <td>Wat is de betekenis van het lied aramsamsam ?</td>\n",
       "      <td>Een interessante vraag!\\n\\n\"Aramsamsam\" (ook w...</td>\n",
       "      <td>Ik kan geen informatie vinden over een lied ge...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>llama-3.1-nemotron-70b-instruct</td>\n",
       "      <td>llama-3.1-405b-instruct-fp8</td>\n",
       "      <td>Afrikaans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>632f631eceb574551ef09a497f77405cbf146fc2e49666...</td>\n",
       "      <td>Vertel me een goede mop</td>\n",
       "      <td>Natuurlijk, hier is een klassieke mop voor je:...</td>\n",
       "      <td>Natuurlijk! Here is a classic Dutch joke for y...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>qwen-plus-0828</td>\n",
       "      <td>deepseek-v2.5</td>\n",
       "      <td>Afrikaans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c35fbab864975e41640e0e384e56c57ecc0c6bb2e4254c...</td>\n",
       "      <td>wat is de populairste bezienswaardigheid van D...</td>\n",
       "      <td>De populairste bezienswaardigheid van Duitslan...</td>\n",
       "      <td>De populairste bezienswaardigheid van Duitslan...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gemini-1.5-pro-002</td>\n",
       "      <td>glm-4-plus</td>\n",
       "      <td>Afrikaans</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0  118c074e1e3880f61f1ecc82b392e6ba250b4cd3bb383f...   \n",
       "1  49aa24778c38c727c3665dd418632176e523999397dc50...   \n",
       "2  5fcf043fe50553461dcd3998c4b0a0d373d404291598ee...   \n",
       "3  632f631eceb574551ef09a497f77405cbf146fc2e49666...   \n",
       "4  c35fbab864975e41640e0e384e56c57ecc0c6bb2e4254c...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0                                     Макроэкономика   \n",
       "1                                    devala maharshi   \n",
       "2      Wat is de betekenis van het lied aramsamsam ?   \n",
       "3                            Vertel me een goede mop   \n",
       "4  wat is de populairste bezienswaardigheid van D...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  ## Макроэкономика: Обзор\\n\\nМакроэкономика - э...   \n",
       "1  Devala Maharshi is a revered figure in Hinduis...   \n",
       "2  Een interessante vraag!\\n\\n\"Aramsamsam\" (ook w...   \n",
       "3  Natuurlijk, hier is een klassieke mop voor je:...   \n",
       "4  De populairste bezienswaardigheid van Duitslan...   \n",
       "\n",
       "                                          response_b   winner  \\\n",
       "0  Макроэкономика — это раздел экономической наук...  model_a   \n",
       "1  Devala Maharshi is a revered sage in Hindu myt...  model_a   \n",
       "2  Ik kan geen informatie vinden over een lied ge...  model_a   \n",
       "3  Natuurlijk! Here is a classic Dutch joke for y...  model_a   \n",
       "4  De populairste bezienswaardigheid van Duitslan...  model_a   \n",
       "\n",
       "                           model_a                      model_b   language  \n",
       "0               gemini-1.5-pro-001            gpt-4o-2024-05-13  Abkhazian  \n",
       "1                    deepseek-v2.5               qwen-plus-0828       Afar  \n",
       "2  llama-3.1-nemotron-70b-instruct  llama-3.1-405b-instruct-fp8  Afrikaans  \n",
       "3                   qwen-plus-0828                deepseek-v2.5  Afrikaans  \n",
       "4               gemini-1.5-pro-002                   glm-4-plus  Afrikaans  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curated_df_v0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(467, 8)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curated_df_v0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save V0 to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "root: str = pathlib.Path().resolve().parent.parent.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kevinmg96/Kaggle competitions/WSDM Cup/multilingual-chatbot-arena/datasets_creator'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_repo_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(root + \"/validation/validation_data_1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Below is a prompt with two possible responses (**Response A** and **Response B**). Evaluate them, select the best one and answer in the following format (it is imperative that you respect the specified format, do not add any more text than what I ask for):\\n1.- Write \\'model_a\\' if the **Response A** is better than **Response B**, otherwise write \\'model_b\\'.\\n\\n**Prompt**:\\nNoix dator Olentzero?\\n\\n**Response A**:\\nOlentzero Euskal Herriko Gabonetako pertsonaia tradizionala da. Jatorriz ikatzgilea zen eta Gabon gauean etxez etxe opariak banatzen zituen umeentzat, Gabonetako Aita bezalako papera betez. Tradizioz Olentzeroren irudia gizon zahar eta gizen bat da, bizarrarekin eta jantzi tradizionalekin. Gaur egun Olentzero Euskal Herriko Gabonetako ospakizunetan presente dago, kalejiretan eta ekitaldietan parte hartuz. Beraz, euskal kulturan oso errotuta dagoen pertsonaia da, umeentzat ilusioa eta magia dakarrena Gabonetako sasoian.\\n\\n**Response B**:\\nOlentzero es una figura tradicional del folclore vasco, que se asemeja a Santa Claus o Papá Noel en la cultura navideña de otras regiones. En el País Vasco y Navarra, Olentzero es quien trae los regalos a los niños el día de Navidad. \\n\\nLa frase \"Noix dator Olentzero?\" parece estar en una mezcla de euskera (vasco) y quizás una interpretación fonética o errónea de otra lengua. Si intentamos corregirla y entenderla en el contexto vasco, podría estar intentando preguntar \"¿Qué nos trae Olentzero?\" o \"¿Qué día viene Olentzero?\", aunque gramaticalmente no es correcto en euskera estándar. \\n\\nEn euskera correcto, podrías preguntar:\\n\\n- **Zer dakar Olentzerok?** - ¿Qué trae Olentzero?\\n- **Noiz dator Olentzero?** - ¿Cuándo viene Olentzero?\\n\\nRecuerda que Olentzero viene la noche del 24 de diciembre, y los regalos se abren generalmente el 25 de diciembre por la mañana. \\n\\nSi tu pregunta estaba orientada a saber más sobre las tradiciones o lo que Olentzero suele traer, aquí tienes un poco más de información:\\n\\n- **Tradiciones:** Olentzero es representado como un carbonero vasco, a veces descrito como un gigante o un hombre de montaña, que baja a los pueblos para anunciar la Navidad. La tradición incluye cantos, desfiles y la preparación de un gran muñeco de Olentzero.\\n\\n- **Regalos:** Al igual que otras figuras navideñas, Olentzero trae regalos a los niños. Estos pueden ser juguetes, libros, ropa, o cualquier cosa que los niños hayan pedido en sus cartas.\\n\\nEspero que esto aclare tu pregunta y te haya proporcionado la información que buscabas sobre Olentzero.\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0]['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "table = pa.Table.from_pandas(curated_df_v0)\n",
    "\n",
    "# Write Arrow Table to Parquet file\n",
    "filename = \"curated_small_v0.parquet\"\n",
    "file = root_repo_directory + c.SLASH + \"data/datasets/curated/\" + filename\n",
    "pq.write_table(table, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curated dataset v1 - Random and  uniform\n",
    "Languages: English, Russian, Chinese, Vietnamese, German, Japanese, Unknown, Korean, Spanish\n",
    "French, Portuguese, Persian, Italian, Turkish,Czech, Arabic, Polish , Ukrainian , Dutch, Hungarian\n",
    "\n",
    "\n",
    "\n",
    "100 samples per language\n",
    "\n",
    "Total samples: 2,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curated dataset v2 - Random and not uniform\n",
    "\n",
    "English, Russian, Chinese, Vietnamese, German, Japanese, Unknown, Korean :  1,000 samples\n",
    "Spanish, French, Portuguese : 500 samples\n",
    "Persian, Italian, Turkish : 200 samples\n",
    "Czech, Arabic, Polish , Ukrainian , Dutch, Hungarian : 100 samples\n",
    "\n",
    "Total samples: 8 * 1,000 + 3 * 500 + 3 * 200 + 6 * 100 = 10,700 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curated dataset v3 - Random,uniform, large multilanguages\n",
    "Languages: English, Russian, Chinese, Vietnamese, German, Japanese, Unknown, Korean, Spanish\n",
    "French, Portuguese, Persian, Italian, Turkish,Czech, Arabic, Polish , Ukrainian , Dutch, Hungarian\n",
    "\n",
    "\n",
    "100 samples per language (above)\n",
    "\n",
    "10 samples per language (below)\n",
    "\n",
    "Indonesian, Slovak, Swedish, Danish, Finnish, Serbian, Bulgarian, Hebrew, Thai, Romanian, Latin,Galician,\n",
    "Norwegian, Catalan, Greek, Lithuanian, Croatian, Sanskrit, Estonian, Scots, Basque       66\n",
    "\n",
    "\n",
    "Total samples: 20 * 100 + 21 * 10 = 2,210 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curated dataset v4 - Random,not uniform, large multilanguages\n",
    "Mix between v2 and v3.\n",
    "\n",
    "respect sampling for the languages composed in V2 and include the specified samples from v3 to the remainiding \n",
    "languages. i,e. up to Hungarian is v2, and from Indonesian and so on is v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curated dataset v5 - Random, not uniform and English biased\n",
    "\n",
    "Same as v2 except that English samples will be 10k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curated dataset v6 - Random,uniform, large multilanguages\n",
    "\n",
    "Same as v3 except that English samples will be 1k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curated dataset v7 - Random, not uniform and English biased\n",
    "\n",
    "Same as v2 except that English samples will be 2k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "English, Russian, Chinese, Vietnamese, German, Japanese, Unknown, Korean :  1,000 samples\n",
    "Spanish, French, Portuguese : 500 samples\n",
    "Persian, Italian, Turkish : 200 samples\n",
    "Czech, Arabic, Polish , Ukrainian , Dutch, Hungarian : 100 samples\n",
    "\n",
    "Total samples: 8 * 1,000 + 3 * 500 + 3 * 200 + 6 * 100 = 10,700 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x,**kwargs):\n",
    "\n",
    "    kwargs['generator'].shuffle(x.to_numpy(),axis= 0)\n",
    "\n",
    "    main_group = [\"Russian\", \"Chinese\", \"Vietnamese\", \"German\", \"Japanese\",  \"Korean\"]\n",
    "    second_group = [\"Spanish\", \"French\", \"Portuguese\"]\n",
    "    third_group = [\"Czech\", \"Arabic\", \"Polish\" , \"Ukrainian\" , \"Dutch\", \"Hungarian\"]\n",
    "\n",
    "    if x.name == \"English\":\n",
    "        return x.iloc[:kwargs[\"english_records\"]]\n",
    "    elif x.name in main_group:\n",
    "        return x.iloc[:1000]\n",
    "    elif x.name in second_group:\n",
    "        return x.iloc[:500]\n",
    "    elif x.name in third_group:\n",
    "        return x.iloc[:100]\n",
    "\n",
    "    return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_v5 = np.random.default_rng(seed=142)\n",
    "kwargs = {'generator' : generator_v5,\"english_records\" : 10000}\n",
    "\n",
    "\n",
    "\n",
    "curated_df_v5 = groupby_language.apply(func,**kwargs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save V5 to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "table = pa.Table.from_pandas(curated_df_v5)\n",
    "\n",
    "# Write Arrow Table to Parquet file\n",
    "filename = \"curated_small_v5.parquet\"\n",
    "file = root_repo_directory + c.SLASH + \"data/datasets/curated/\" + filename\n",
    "pq.write_table(table, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33736/3857405990.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  curated_df_v7 = groupby_language.apply(func,**kwargs).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "generator_v7 = np.random.default_rng(seed=142)\n",
    "kwargs = {'generator' : generator_v7, \"english_records\" : 2000}\n",
    "\n",
    "\n",
    "\n",
    "curated_df_v7 = groupby_language.apply(func,**kwargs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save V7 to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "table = pa.Table.from_pandas(curated_df_v7)\n",
    "\n",
    "# Write Arrow Table to Parquet file\n",
    "filename = \"curated_small_v7.parquet\"\n",
    "file = root_repo_directory + c.SLASH + \"data/datasets/curated/\" + filename\n",
    "pq.write_table(table, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curated dataset v8 - Random, uniform, filter by token size\n",
    "\n",
    "First filter: Conserve records whose prompt has less than 3.5k tokens\n",
    "\n",
    "Second filter: \n",
    "Languages: English, Russian, Chinese, Vietnamese, German, Japanese, Unknown, Korean, Spanish\n",
    "French, Portuguese, Persian, Italian, Turkish,Czech, Arabic, Polish , Ukrainian , Dutch, Hungarian\n",
    "\n",
    "100 samples per language (if possible)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_TEMPLATE = 'You are a specialist in evaluating multilingual chat responses, with a focus on comparing and ranking outputs from different LLMs. Your primary goal is to determine which response is more likely to be preferred by humans based on factors such as clarity, relevance, tone, and overall quality.\\n'\n",
    "PROMPT_TEMPLATE = \"\"\"Below is a prompt with two possible responses (**Response A** and **Response B**). Evaluate them, select the best one and answer in the following format (it is imperative that you respect the specified format, do not add any more text than what I ask for):\\n1.- Write 'model_a' if the **Response A** is better than **Response B**, otherwise write 'model_b'.\\n\\n**Prompt**:\\n{prompt}\\n\\n**Response A**:\\n{response_a}\\n\\n**Response B**:\\n{response_b}\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model_name = \"Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "model_name,padding_side=\"left\",legacy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prompt_num_tokens(x,**kwargs):\n",
    "    tokenizer = kwargs[\"tokenizer\"]\n",
    "\n",
    "    messages = [\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_TEMPLATE},\n",
    "                    {\"role\" : \"user\", \"content\" : PROMPT_TEMPLATE.format(\n",
    "                    prompt=x.prompt,response_a=x.response_a,response_b = x.response_b)},\n",
    "                    {\"role\" : \"assistant\", \"content\" : x.winner}\n",
    "                ]\n",
    "    return len(tokenizer.apply_chat_template(messages,add_generation_prompt=True,tokenize=True))\n",
    "\n",
    "kwargs = {\n",
    "    \"tokenizer\" :tokenizer\n",
    "}\n",
    "train_df[\"num_tokens\"] = train_df.apply(add_prompt_num_tokens,axis=1,**kwargs)\n",
    "\n",
    "train_df[\"num_tokens_categories\"] = pd.cut(train_df[\"num_tokens\"],10,labels=np.arange(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_172504/1205359606.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  curated_df_v8 = group_num_tokens_subset.apply(func,**kwargs).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "num_tokens_subset =train_df.query('num_tokens_categories == 0')\n",
    "group_num_tokens_subset =num_tokens_subset.groupby(\"language\")\n",
    "\n",
    "def func(x,**kwargs):\n",
    "\n",
    "    kwargs['generator'].shuffle(x.to_numpy(),axis= 0)\n",
    "\n",
    "\n",
    "    group = [\"English\",\"Russian\", \"Chinese\", \"Vietnamese\", \"German\", \"Japanese\",  \"Korean\",\n",
    "                  \"Spanish\", \"French\", \"Portuguese\",\"Persian\", \"Italian\", \"Turkish\",\n",
    "                    \"Czech\", \"Arabic\", \"Polish\" , \"Ukrainian\" , \"Dutch\", \"Hungarian\"]\n",
    "\n",
    "\n",
    "    if x.name in group:\n",
    "        return x.iloc[:kwargs[\"num_records\"]]\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "num_records = 100\n",
    "generator = np.random.default_rng(seed=142)\n",
    "kwargs = {\"num_records\" : num_records, 'generator' : generator}\n",
    "\n",
    "\n",
    "curated_df_v8 = group_num_tokens_subset.apply(func,**kwargs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save V8 to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(curated_df_v8)\n",
    "\n",
    "# Write Arrow Table to Parquet file\n",
    "filename = \"curated_small_v8.parquet\"\n",
    "file = root_repo_directory + c.SLASH + \"data/datasets/curated/\" + filename\n",
    "pq.write_table(table, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsdm-cup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
